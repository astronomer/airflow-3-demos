# You need an AWS connection for:
# - storing the newsletter in S3
# - event-driven scheduling via SQS
# - using an XCom backend with S3
AIRFLOW_CONN_AWS_DEFAULT='{
    "conn_type":"aws",
    "login":"<your_aws_access_key_id>",
    "password":"<your_aws_secret_access_key>",
    "extra": {
        "region_name":"<your_aws_region>"  # the region is needed for SQS!
    }
}'


# Variables to store the newsletter in cloud object storage instead of the
# local filesystem defaults
OBJECT_STORAGE_CONN_ID="<your_object_storage_conn_id>"
OBJECT_STORAGE_SYSTEM="s3"
OBJECT_STORAGE_PATH_NEWSLETTER="<your_object_storage_path_newsletter>"
OBJECT_STORAGE_PATH_USER_INFO="<your_object_storage_path_user_info>"


# Variables to set up a custom xcom backend
AIRFLOW__CORE__XCOM_BACKEND="<your_airflow_xcom_backend>"
AIRFLOW__COMMON_IO__XCOM_OBJECTSTORAGE_PATH="<your_xcom_objectstorage_path>"
AIRFLOW__COMMON_IO__XCOM_OBJECTSTORAGE_THRESHOLD=<your_xcom_objectstorage_threshold>

# Variables to set up inference execution / event-driven scheduling
SQS_QUEUE_URL="<your_sqs_queue_url>"


# You need a connection to OpenAI for:
# - generating the newsletter content 
AIRFLOW_CONN_MY_OPENAI_CONN='{
    "conn_type":"openai",
    "password":"<your_openai_api_key>"
}'